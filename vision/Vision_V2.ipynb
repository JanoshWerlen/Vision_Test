{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv \n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"openai.api_key\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_response = []\n",
    "messages = []\n",
    "llm = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _openai(input) -> str:\n",
    "    response = openai.chat.completions.create(\n",
    "    model=\"gpt-4-vision-preview\",\n",
    "    messages=input,\n",
    "    )\n",
    "    ai_response.append(response.choices[0].message.content)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####LOCAL AI WITH SCREENSHOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "\n",
    "\n",
    "def _openai_local(prompt: str, image: str):\n",
    "    # Path to your image\n",
    "    image_path = image\n",
    "\n",
    "    # Getting the base64 string\n",
    "    base64_image = encode_image(image_path)\n",
    "\n",
    "    headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {openai.api_key}\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "    \"model\": \"gpt-4-vision-preview\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": prompt\n",
    "            },\n",
    "            {\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                \"detail\": \"low\"\n",
    "            }\n",
    "            }\n",
    "        ]\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 300\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    \n",
    "    return (response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-98lnfvFsoqFVCF6X1HubT6h7i6Tl1', 'object': 'chat.completion', 'created': 1711877395, 'model': 'gpt-4-1106-vision-preview', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': \"I'm sorry, but I can't assist with that request.\"}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 162, 'completion_tokens': 13, 'total_tokens': 175}, 'system_fingerprint': None}\n"
     ]
    }
   ],
   "source": [
    "image = \"screenshot.png\"\n",
    "prompt = \"Analyze the provided 512x512 pixel image for a CAPTCHA button, typically used to confirm a user is not a bot. Identify the button's central point and provide its coordinates in terms of X and Y axis within this image size. The coordinates should help locate the button's center, which needs to be pressed to pass the CAPTCHA.\"\n",
    "\n",
    "response = _openai_local(prompt, image)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Response.json of <Response [200]>>\n"
     ]
    }
   ],
   "source": [
    "print(response.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request(image_url: str, prompt:str)-> str:\n",
    "        messages.append ({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": image_url,\n",
    "                },\n",
    "                },\n",
    "            ],\n",
    "            }\n",
    "            )\n",
    "        return _openai(messages)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_markdown_code_block_markers(text):\n",
    "    # Define the markers\n",
    "    start_marker = \"```json\"\n",
    "    end_marker = \"```\"\n",
    "\n",
    "    # Remove the start marker\n",
    "    if text.startswith(start_marker):\n",
    "        text = text[len(start_marker):]\n",
    "\n",
    "    # Remove the end marker\n",
    "    if text.endswith(end_marker):\n",
    "        text = text[:-len(end_marker)]\n",
    "\n",
    "    return text.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_to_json(prompt):\n",
    "\n",
    "\n",
    "  response = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    response_format={ \"type\": \"json_object\" },\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to output JSON.\"},\n",
    "      {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "  )\n",
    "  print(response.choices[0].message.content)\n",
    "  to_safe = response.choices[0].message.content\n",
    "  return to_safe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extratcion_prompt = \"\"\"Please analyze the image and generate a JSON object describing the social situation depicted. \n",
    "Your response should include details about the individuals present, their activities, and identifiable characteristics. \n",
    "Include a timestamp and format your response as a JSON object with the following attributes for each person: ID, position, activity, age, skincolor, clothing, posture, \n",
    "facial_expression, observable_features. Please use the following JSON structure as a template and dont return anything else, no disclaimers: \n",
    "{\n",
    "  \"timestamp\": \"current time\", \n",
    "  \"persons\": [\n",
    "    {\n",
    "      \"ID\": \"\",\n",
    "      \"position\": \"\",\n",
    "      \"activity\": \"\",\n",
    "      \"age\": \"\",\n",
    "      \"sex\": \"\",\n",
    "      \"mood\": \"\",\n",
    "      \"skincolor\": \"\",\n",
    "      \"clothing\": {\n",
    "        \"upper-body\": \"\",\n",
    "        \"lower-body\": \"\",\n",
    "        \"headwear\": \"\"\n",
    "      },\n",
    "      \"posture\": \"\",\n",
    "      \"facial_expression\": \"\",\n",
    "      \"observable_features\": {\n",
    "        \"hairstyle\": \"\",\n",
    "        \"haircolor\": \"\",\n",
    "        \"accessories\": \"\"\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(image_url: str) -> str:\n",
    "    return request(\n",
    "        image_url=image_url,\n",
    "        prompt = \n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def recognise(image_url:str, person_desciption:str)->str: \n",
    "    return request(\n",
    "        image_url= image_url,\n",
    "        prompt= f\"\"\"Try to identify a specific person using this description: {person_desciption} in the new image. \n",
    "        Focus on matching features such as cothing, hairstyle, facial expressions, posture, and any unique identifiers \n",
    "        that were previously noted. Describe how each observable feature in the new image aligns with the information in the \n",
    "        JSON object to confirm the identity of the person. If the person is present, provide additional information about that person\n",
    "        and try to conclude what has happened between the two pictures given the time difference between the pictures is 5 seconds. \n",
    "        If the Person is not present. Simply respone with 'the person does not seem to be in the picture' Answer as text\"\"\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****USAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction = extract(\"screenshot.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"timestamp\": \"2023-04-12T12:00:00Z\", \n",
      "  \"persons\": [\n",
      "    {\n",
      "      \"ID\": \"Person1\",\n",
      "      \"position\": \"left\",\n",
      "      \"activity\": \"posing for a photo\",\n",
      "      \"age\": \"adult\",\n",
      "      \"skincolor\": \"light\",\n",
      "      \"clothing\": {\n",
      "        \"upper-body\": \"light-colored shirt\",\n",
      "        \"lower-body\": \"dark pants\",\n",
      "        \"headwear\": \"sunglasses\"\n",
      "      },\n",
      "      \"posture\": \"standing\",\n",
      "      \"facial_expression\": \"smiling\",\n",
      "      \"observable_features\": {\n",
      "        \"hairstyle\": \"short\",\n",
      "        \"haircolor\": \"dark\",\n",
      "        \"accessories\": \"watch on left wrist\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"ID\": \"Person2\",\n",
      "      \"position\": \"center-left\",\n",
      "      \"activity\": \"posing for a photo\",\n",
      "      \"age\": \"child\",\n",
      "      \"skincolor\": \"light\",\n",
      "      \"clothing\": {\n",
      "        \"upper-body\": \"red traditional outfit\",\n",
      "        \"lower-body\": \"red traditional outfit\",\n",
      "        \"headwear\": \"none\"\n",
      "      },\n",
      "      \"posture\": \"standing\",\n",
      "      \"facial_expression\": \"smiling\",\n",
      "      \"observable_features\": {\n",
      "        \"hairstyle\": \"short\",\n",
      "        \"haircolor\": \"dark\",\n",
      "        \"accessories\": \"none\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"ID\": \"Person3\",\n",
      "      \"position\": \"center-right\",\n",
      "      \"activity\": \"posing for a photo\",\n",
      "      \"age\": \"adult\",\n",
      "      \"skincolor\": \"light\",\n",
      "      \"clothing\": {\n",
      "        \"upper-body\": \"red dress\",\n",
      "        \"lower-body\": \"red dress\",\n",
      "        \"headwear\": \"none\"\n",
      "      },\n",
      "      \"posture\": \"standing\",\n",
      "      \"facial_expression\": \"smiling\",\n",
      "      \"observable_features\": {\n",
      "        \"hairstyle\": \"long\",\n",
      "        \"haircolor\": \"dark\",\n",
      "        \"accessories\": \"bracelet on right wrist\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"ID\": \"Person4\",\n",
      "      \"position\": \"right\",\n",
      "      \"activity\": \"posing for a photo\",\n",
      "      \"age\": \"young adult\",\n",
      "      \"skincolor\": \"light\",\n",
      "      \"clothing\": {\n",
      "        \"upper-body\": \"red traditional outfit\",\n",
      "        \"lower-body\": \"red traditional outfit\",\n",
      "        \"headwear\": \"none\"\n",
      "      },\n",
      "      \"posture\": \"standing\",\n",
      "      \"facial_expression\": \"smiling\",\n",
      "      \"observable_features\": {\n",
      "        \"hairstyle\": \"long\",\n",
      "        \"haircolor\": \"dark\",\n",
      "        \"accessories\": \"earrings\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "Please note that attributes like age and skincolor are assumed based on visual estimation and could be inaccurate. The timestamp provided is just an example and should be set to the actual time when the analysis is performed.\n"
     ]
    }
   ],
   "source": [
    "extraction = remove_markdown_code_block_markers(extraction)\n",
    "print(extraction)\n",
    "\n",
    "file_path = 'Extraction.json'\n",
    "\n",
    "# Write the data to the file in JSON format\n",
    "with open(file_path, 'a') as file:\n",
    "    json.dump(extraction, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['```json\\n{\\n  \"timestamp\": \"2023-04-12T12:00:00Z\", \\n  \"persons\": [\\n    {\\n      \"ID\": \"Person1\",\\n      \"position\": \"left\",\\n      \"activity\": \"posing for a photo\",\\n      \"age\": \"adult\",\\n      \"skincolor\": \"light\",\\n      \"clothing\": {\\n        \"upper-body\": \"light-colored shirt\",\\n        \"lower-body\": \"dark pants\",\\n        \"headwear\": \"sunglasses\"\\n      },\\n      \"posture\": \"standing\",\\n      \"facial_expression\": \"smiling\",\\n      \"observable_features\": {\\n        \"hairstyle\": \"short\",\\n        \"haircolor\": \"dark\",\\n        \"accessories\": \"watch on left wrist\"\\n      }\\n    },\\n    {\\n      \"ID\": \"Person2\",\\n      \"position\": \"center-left\",\\n      \"activity\": \"posing for a photo\",\\n      \"age\": \"child\",\\n      \"skincolor\": \"light\",\\n      \"clothing\": {\\n        \"upper-body\": \"red traditional outfit\",\\n        \"lower-body\": \"red traditional outfit\",\\n        \"headwear\": \"none\"\\n      },\\n      \"posture\": \"standing\",\\n      \"facial_expression\": \"smiling\",\\n      \"observable_features\": {\\n        \"hairstyle\": \"short\",\\n        \"haircolor\": \"dark\",\\n        \"accessories\": \"none\"\\n      }\\n    },\\n    {\\n      \"ID\": \"Person3\",\\n      \"position\": \"center-right\",\\n      \"activity\": \"posing for a photo\",\\n      \"age\": \"adult\",\\n      \"skincolor\": \"light\",\\n      \"clothing\": {\\n        \"upper-body\": \"red dress\",\\n        \"lower-body\": \"red dress\",\\n        \"headwear\": \"none\"\\n      },\\n      \"posture\": \"standing\",\\n      \"facial_expression\": \"smiling\",\\n      \"observable_features\": {\\n        \"hairstyle\": \"long\",\\n        \"haircolor\": \"dark\",\\n        \"accessories\": \"bracelet on right wrist\"\\n      }\\n    },\\n    {\\n      \"ID\": \"Person4\",\\n      \"position\": \"right\",\\n      \"activity\": \"posing for a photo\",\\n      \"age\": \"young adult\",\\n      \"skincolor\": \"light\",\\n      \"clothing\": {\\n        \"upper-body\": \"red traditional outfit\",\\n        \"lower-body\": \"red traditional outfit\",\\n        \"headwear\": \"none\"\\n      },\\n      \"posture\": \"standing\",\\n      \"facial_expression\": \"smiling\",\\n      \"observable_features\": {\\n        \"hairstyle\": \"long\",\\n        \"haircolor\": \"dark\",\\n        \"accessories\": \"earrings\"\\n      }\\n    }\\n  ]\\n}\\n```\\nPlease note that attributes like age and skincolor are assumed based on visual estimation and could be inaccurate. The timestamp provided is just an example and should be set to the actual time when the analysis is performed.', 'Based on the description provided, we are looking for a male individual with short hair, white skin potentially possessing an Asian appearance, who is characterized as being well-dressed.\\n\\nThe new image displays a group of four individuals walking down a street. There is one male adult who matches the description:\\n\\n- His skin tone could be described as white, and he may have an Asian appearance.\\n- This individual has short hair.\\n- He is well-dressed, sporting a light-colored, long-sleeve shirt and dark trousers.\\n\\nObservable features that confirm this match include:\\n- Clothing: He is wearing the same light-colored long-sleeve shirt and dark trousers as mentioned in the description, indicating a well-dressed appearance.\\n- Hairstyle: The short hair matches the description.\\n- Facial expression and posture: Since the time difference between the images is only five seconds, the facial expression and posture are likely to be similar.\\n\\nGiven the consistency of these features with the description, we can confirm that the person is present in the new image. In the span of the 5 seconds between the two pictures, the group appears to have started walking down the street, engaging in a conversation or interaction that looks friendly and familial, as indicated by their proximity and relaxed demeanor.']\n"
     ]
    }
   ],
   "source": [
    "print(ai_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"Return the 'content' in this: {extraction} as a JSON\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"persons\": [\n",
      "        {\n",
      "            \"position\": \"left\",\n",
      "            \"activity\": \"holding a child\",\n",
      "            \"age\": \"adult\",\n",
      "            \"skincolor\": \"brown\",\n",
      "            \"clothing\": {\n",
      "                \"upper-body\": \"grey raglan shirt with black sleeves\",\n",
      "                \"lower-body\": \"dark blue jeans\",\n",
      "                \"headwear\": \"\"\n",
      "            },\n",
      "            \"posture\": \"sitting\",\n",
      "            \"facial_expression\": \"smiling\",\n",
      "            \"observable_features\": {\n",
      "                \"hairstyle\": \"short\",\n",
      "                \"haircolor\": \"black\",\n",
      "                \"accessories\": \"glasses\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"position\": \"center\",\n",
      "            \"activity\": \"being held\",\n",
      "            \"age\": \"infant\",\n",
      "            \"skincolor\": \"brown\",\n",
      "            \"clothing\": {\n",
      "                \"upper-body\": \"white shirt with blue dots\",\n",
      "                \"lower-body\": \"blue shorts\",\n",
      "                \"headwear\": \"\"\n",
      "            },\n",
      "            \"posture\": \"sitting on lap\",\n",
      "            \"facial_expression\": \"smiling\",\n",
      "            \"observable_features\": {\n",
      "                \"hairstyle\": \"short curly\",\n",
      "                \"haircolor\": \"black\",\n",
      "                \"accessories\": \"\"\n",
      "            }\n",
      "        },\n",
      "        {\n",
      "            \"position\": \"right\",\n",
      "            \"activity\": \"sitting next to family\",\n",
      "            \"age\": \"adult\",\n",
      "            \"skincolor\": \"brown\",\n",
      "            \"clothing\": {\n",
      "                \"upper-body\": \"black and white striped shirt\",\n",
      "                \"lower-body\": \"black pants\",\n",
      "                \"headwear\": \"\"\n",
      "            },\n",
      "            \"posture\": \"sitting\",\n",
      "            \"facial_expression\": \"smiling\",\n",
      "            \"observable_features\": {\n",
      "                \"hairstyle\": \"shoulder-length\",\n",
      "                \"haircolor\": \"black\",\n",
      "                \"accessories\": \"glasses\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "to_safe = turn_to_json(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = \"https://images.unsplash.com/photo-1655185497004-f3018eab9cb8?w=400&auto=format&fit=crop&q=60&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxjb2xsZWN0aW9uLXBhZ2V8MzR8MzgyOTE2OXx8ZW58MHx8fHx8\"\n",
    "\n",
    "desc = \"\"\"Male, short hair, white skin, could be asian in apperance, usually well dressed\"\"\"\n",
    "\n",
    "recognision = recognise (img, desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the description provided, we are looking for a male individual with short hair, white skin potentially possessing an Asian appearance, who is characterized as being well-dressed.\n",
      "\n",
      "The new image displays a group of four individuals walking down a street. There is one male adult who matches the description:\n",
      "\n",
      "- His skin tone could be described as white, and he may have an Asian appearance.\n",
      "- This individual has short hair.\n",
      "- He is well-dressed, sporting a light-colored, long-sleeve shirt and dark trousers.\n",
      "\n",
      "Observable features that confirm this match include:\n",
      "- Clothing: He is wearing the same light-colored long-sleeve shirt and dark trousers as mentioned in the description, indicating a well-dressed appearance.\n",
      "- Hairstyle: The short hair matches the description.\n",
      "- Facial expression and posture: Since the time difference between the images is only five seconds, the facial expression and posture are likely to be similar.\n",
      "\n",
      "Given the consistency of these features with the description, we can confirm that the person is present in the new image. In the span of the 5 seconds between the two pictures, the group appears to have started walking down the street, engaging in a conversation or interaction that looks friendly and familial, as indicated by their proximity and relaxed demeanor.\n"
     ]
    }
   ],
   "source": [
    "print(recognision)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
