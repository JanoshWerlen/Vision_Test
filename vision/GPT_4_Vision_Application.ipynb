{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv \n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"openai.api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Reusable Code\n",
    "\n",
    "def _openai() -> str:\n",
    "    response = openai.chat.completions.create(\n",
    "    model=\"gpt-4-vision-preview\",\n",
    "    messages=messages,\n",
    "    max_tokens=300,\n",
    "    )\n",
    "\n",
    "    return response.choices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request(image_url: str, prompt:str, type)-> str:\n",
    "    if type == \"E\":\n",
    "        messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": image_url,\n",
    "                },\n",
    "                },\n",
    "            ],\n",
    "            }\n",
    "            )\n",
    "        _openai()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(image_url:str) -> str:\n",
    "    return request(\n",
    "        image_url= image_url,\n",
    "        prompt=\"Please analyze this picture and identify the social situation it depicts. Provide a detailed description of the scene, including the people present, their activities, and any notable features or characteristics. Your response should be formatted as a JSON object. The JSON should have a key named 'persons', which contains a list of individual person objects. Each person object should detail the person's activities and include descriptive elements such as clothing, posture, facial expressions, and any other observable features that would aid in recognizing them in a different picture.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': [{'type': 'text', 'text': \"Please analyze this picture and identify the social situation it depicts. Provide a detailed description of the scene, including the people present, their activities, and any notable features or characteristics. Your response should be formatted as a JSON object. The JSON should have a key named 'persons', which contains a list of individual person objects. Each person object should detail the person's activities and include descriptive elements such as clothing, posture, facial expressions, and any other observable features that would aid in recognizing them in a different picture.\"}, {'type': 'image_url', 'image_url': {'url': 'https://image.cnbcfm.com/api/v1/image/107295167-1693591029492-gettyimages-1522419916-a7409294.jpeg?v=1693839601&w=630&h=354&ffmt=webp&vtcrop=y'}}]}, {'role': 'user', 'content': [{'type': 'text', 'text': \"Please analyze this picture and identify the social situation it depicts. Provide a detailed description of the scene, including the people present, their activities, and any notable features or characteristics. Your response should be formatted as a JSON object. The JSON should have a key named 'persons', which contains a list of individual person objects. Each person object should detail the person's activities and include descriptive elements such as clothing, posture, facial expressions, and any other observable features that would aid in recognizing them in a different picture.\"}, {'type': 'image_url', 'image_url': {'url': 'https://image.cnbcfm.com/api/v1/image/107295167-1693591029492-gettyimages-1522419916-a7409294.jpeg?v=1693839601&w=630&h=354&ffmt=webp&vtcrop=y'}}]}]\n"
     ]
    }
   ],
   "source": [
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognise(image_url:str, person_desciption:str)->str: \n",
    "    return request(\n",
    "        image_url= image_url,\n",
    "        prompt= f\"Using the information from the previously analyzed picture, please identify a specific person using this description: {person_desciption} in a new image. Refer to the detailed descriptions from the 'persons' list in the provided serialized JSON object that can be safed in a JSON file. Focus on matching features such as clothing, hairstyle, facial expressions, posture, and any unique identifiers that were previously noted. Describe how each observable feature in the new image aligns with the information in the JSON object to confirm the identity of the person. If the person is present, provide additional information about that person.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_situation: str = extract(\"https://image.cnbcfm.com/api/v1/image/107295167-1693591029492-gettyimages-1522419916-a7409294.jpeg?v=1693839601&w=630&h=354&ffmt=webp&vtcrop=y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type Choice is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Write the data to the file in JSON format\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m----> 7\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.12.1\\Lib\\json\\__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[0;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[0;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[0;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.12.1\\Lib\\json\\encoder.py:439\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    438\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[1;32m--> 439\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.12.1\\Lib\\json\\encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[0;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m \n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    181\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type Choice is not JSON serializable"
     ]
    }
   ],
   "source": [
    "def choice_to_dict(choice_object):\n",
    "    # This function should be adapted based on the structure of the Choice object\n",
    "    # Example structure, adjust according to actual attributes\n",
    "    return {\n",
    "        'finish_reason': choice_object.finish_reason,\n",
    "        'index': choice_object.index,\n",
    "        'logprobs': choice_object.logprobs,\n",
    "        'content': choice_object.message.content\n",
    "        # Add other necessary fields here\n",
    "    }\n",
    "\n",
    "# Assuming _openai() returns an instance of the Choice class\n",
    "data = _openai()\n",
    "\n",
    "# Convert the Choice object to a dictionary\n",
    "serializable_data = choice_to_dict(data)\n",
    "\n",
    "file_path = 'Response_Vault.txt'\n",
    "\n",
    "# Write the data to the file in JSON format\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(serializable_data, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='```json\\n{\\n  \"persons\": [\\n    {\\n      \"description\": \"Woman on the left with curly hair\",\\n      \"activities\": \"Laughing and leaning towards the center\",\\n      \"clothing\": \"Wearing a green, long-sleeve top\",\\n      \"posture\": \"Leaning forward slightly\",\\n      \"facial_expression\": \"Joyful with eyes slightly closed\",\\n      \"observable_features\": [\\n        \"Curly hair\",\\n        \"Green top\",\\n        \"Left arm raised\"\\n      ]\\n    },\\n    {\\n      \"description\": \"Woman in the center holding a bowl\",\\n      \"activities\": \"Smiling and holding a bowl of popcorn\",\\n      \"clothing\": \"Wearing a plaid shirt\",\\n      \"posture\": \"Sitting back and relaxed\",\\n      \"facial_expression\": \"Happy with teeth visible\",\\n      \"observable_features\": [\\n        \"Blond hair\",\\n        \"Plaid shirt\",\\n        \"Holding a bowl\"\\n      ]\\n    },\\n    {\\n      \"description\": \"Woman on the right\",\\n      \"activities\": \"Laughing and engaging in conversation\",\\n      \"clothing\": \"Wearing a pink shirt\",\\n      \"posture\": \"Upright\",\\n      \"facial_expression\": \"Very happy with an open smile\",\\n      \"observable_features\": [\\n        \"Black curly hair\",\\n        \"Pink top\",\\n        \"Visible earrings\"\\n      ]\\n    },\\n    {\\n      \"description\": \"Partially visible person on the', role='assistant', function_call=None, tool_calls=None))\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'persons'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m social_situation: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m extract(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://image.cnbcfm.com/api/v1/image/107295167-1693591029492-gettyimages-1522419916-a7409294.jpeg?v=1693839601&w=630&h=354&ffmt=webp&vtcrop=y\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m person_tobedetected \u001b[38;5;241m=\u001b[39m \u001b[43msocial_situation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpersons\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      3\u001b[0m recognision \u001b[38;5;241m=\u001b[39m recognise(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m, person_tobedetected)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'persons'"
     ]
    }
   ],
   "source": [
    "\n",
    "person_tobedetected = social_situation.persons[0]\n",
    "recognision = recognise(\"...\", person_tobedetected)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
